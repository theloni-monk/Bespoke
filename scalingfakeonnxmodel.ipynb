{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import helper\n",
    "from onnx import TensorProto\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is:\n",
      "ir_version: 9\n",
      "graph {\n",
      "  node {\n",
      "    input: \"X_0\"\n",
      "    input: \"weight_0\"\n",
      "    output: \"XMM32_0\"\n",
      "    name: \"mm_0\"\n",
      "    op_type: \"MatMulInteger\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"XMM32_0\"\n",
      "    input: \"bias_0\"\n",
      "    output: \"XMMB32_0\"\n",
      "    name: \"add_0\"\n",
      "    op_type: \"Add\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"XMMB32_0\"\n",
      "    output: \"XMMB8_0\"\n",
      "    op_type: \"Cast\"\n",
      "    attribute {\n",
      "      name: \"to\"\n",
      "      i: 3\n",
      "      type: INT\n",
      "    }\n",
      "  }\n",
      "  node {\n",
      "    input: \"XMMB8_0\"\n",
      "    output: \"Y_0\"\n",
      "    name: \"relu_0\"\n",
      "    op_type: \"Relu\"\n",
      "  }\n",
      "  name: \"testmodel_0\"\n",
      "  initializer {\n",
      "    dims: 8\n",
      "    dims: 8\n",
      "    data_type: 3\n",
      "    name: \"weight_0\"\n",
      "    raw_data: \"\\030\\204\\214\\363e\\256-\\201^L)X\\222\\364\\357-)oI<VK^-\\343\\030\\271o\\201\\026\\005\\213\\242\\272\\225\\320\\304\\026\\357\\203h\\322\\374#J\\240-\\310u\\245/\\300\\1773+\\245\\177\\r\\000\\334x\\227h3\"\n",
      "  }\n",
      "  initializer {\n",
      "    dims: 8\n",
      "    data_type: 6\n",
      "    name: \"bias_0\"\n",
      "    raw_data: \"\\254\\377\\377\\377\\361\\377\\377\\377\\257\\377\\377\\377\\300\\377\\377\\377\\226\\377\\377\\377\\276\\377\\377\\377!\\000\\000\\000\\271\\377\\377\\377\"\n",
      "  }\n",
      "  input {\n",
      "    name: \"X_0\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 3\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_value: 8\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y_0\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 3\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_value: 8\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "opset_import {\n",
      "  version: 19\n",
      "}\n",
      "\n",
      "The model is checked!\n"
     ]
    }
   ],
   "source": [
    "def make_layer(in_dim, out_dim, idx):\n",
    "    # Create one input (ValueInfoPro    to)\n",
    "    X = helper.make_tensor_value_info(f\"X_{idx}\", TensorProto.INT8, [in_dim])\n",
    "    w = helper.make_tensor(f\"weight_{idx}\", TensorProto.INT8, [out_dim, in_dim], np.random.randint(-128, 128, (out_dim, in_dim)).astype(np.int8).tobytes(), raw=True)\n",
    "    b = helper.make_tensor(f\"bias_{idx}\", TensorProto.INT32, [out_dim], np.random.randint(-128, 128, (out_dim)).astype(np.int32).tobytes(),  raw=True)\n",
    "\n",
    "    # Create one output (ValueInfoProto)\n",
    "    Y = helper.make_tensor_value_info(f\"Y_{idx}\", TensorProto.INT8, [out_dim])\n",
    "\n",
    "    mmnode = helper.make_node(\n",
    "        \"MatMulInteger\",\n",
    "        [f\"X_{idx}\", f\"weight_{idx}\"],\n",
    "        [f\"XMM32_{idx}\"],\n",
    "        name=f\"mm_{idx}\"\n",
    "    )\n",
    "\n",
    "    biasnode = helper.make_node(\n",
    "        \"Add\",\n",
    "        [f\"XMM32_{idx}\", f\"bias_{idx}\"],\n",
    "        [f\"XMMB32_{idx}\"],\n",
    "        name=f\"add_{idx}\"\n",
    "    )\n",
    "\n",
    "    castnode = helper.make_node( #FIXME: cast truncates bits\n",
    "        \"Cast\",\n",
    "        [f\"XMMB32_{idx}\"],\n",
    "        [f\"XMMB8_{idx}\"],\n",
    "        to=TensorProto.INT8\n",
    "    )\n",
    "\n",
    "    relunode = helper.make_node(\n",
    "        \"Relu\",\n",
    "        [f\"XMMB8_{idx}\"],\n",
    "        [f\"Y_{idx}\"],\n",
    "        name=f\"relu_{idx}\"\n",
    "    )\n",
    "\n",
    "    # Create the graph (GraphProto)\n",
    "    graph_def = helper.make_graph(\n",
    "        [mmnode,  biasnode, castnode, relunode],\n",
    "        f\"testmodel_{idx}\",\n",
    "        [X],\n",
    "        [Y],\n",
    "        [w, b]\n",
    "    )\n",
    "\n",
    "    # Create the model (ModelProto)\n",
    "    opset = onnx.OperatorSetIdProto()\n",
    "    opset.version = 19\n",
    "    return helper.make_model(graph_def, opset_imports = [opset])\n",
    "\n",
    "model_def = make_layer(8, 8, 0)\n",
    "print(f\"The model is:\\n{model_def}\")\n",
    "onnx.checker.check_model(model_def)\n",
    "onnx.shape_inference.infer_shapes(model_def, check_type=True, strict_mode=True, data_prop=True)\n",
    "print(\"The model is checked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 12, 40, 60, 126, 168, 288, 360, 550]\n",
      "[110, 132, 156, 182, 210, 240, 272, 306, 342, 380, 420, 462, 506, 552, 600, 650, 702, 756, 812, 870, 930, 992, 1056, 1122, 1190, 1260, 1332, 1406, 1482, 1560, 1640, 1722, 1806, 1892, 1980, 2070, 2162, 2256, 2352, 2450, 2550, 2652, 2756, 2862, 2970, 3080, 3192, 3306, 3422, 3540, 3660, 3782, 3906, 4032, 4160, 4290, 4422, 4556, 4692, 4830, 4970, 5112, 5256, 5402, 5550, 5700, 5852, 6006, 6162, 6320, 6480, 6642, 6806, 6972, 7140, 7310, 7482, 7656, 7832, 8010, 8190, 8372, 8556, 8742, 8930, 9120, 9312, 9506, 9702, 9900, 10100, 10302, 10506, 10712, 10920, 11130, 11342, 11556, 11772, 11990, 12210, 12432, 12656, 12882, 13110, 13340, 13572, 13806, 14042, 14280, 14520, 14762, 15006, 15252, 15500, 15750, 16002, 16256, 16512, 16770, 17030, 17292, 17556, 17822, 18090, 18360, 18632, 18906, 19182, 19460, 19740, 20022, 20306, 20592, 20880, 21170, 21462, 21756, 22052, 22350, 22650, 22952, 23256, 23562, 23870, 24180, 24492, 24806, 25122, 25440, 25760, 26082, 26406, 26732, 27060, 27390, 27722, 28056, 28392, 28730, 29070, 29412, 29756, 30102, 30450, 30800, 31152, 31506, 31862, 32220, 32580, 32942, 33306, 33672, 34040, 34410, 34782, 35156, 35532, 35910, 36290, 36672, 37056, 37442, 37830, 38220, 38612, 39006, 39402, 39800, 40200, 40602, 41006, 41412, 41820, 42230, 42642, 43056, 43472, 43890, 44310, 44732, 45156, 45582, 46010, 46440, 46872, 47306, 47742, 48180, 48620, 49062, 49506, 49952, 50400, 50850, 51302, 51756, 52212, 52670, 53130, 53592, 54056, 54522, 54990, 55460, 55932, 56406, 56882, 57360, 57840, 58322, 58806, 59292, 59780, 60270, 60762, 61256, 61752, 62250]\n"
     ]
    }
   ],
   "source": [
    "def make_multilayer(n_layers, layer_widths = None):\n",
    "    if layer_widths == None:\n",
    "        layer_widths = [n_layers for _ in range(2*n_layers)]\n",
    "    layers = [make_layer(layer_widths[2*i], layer_widths[2*i+1], i) for i in range(n_layers)]\n",
    "    n_params = sum(layer_widths[2*i]*layer_widths[2*i + 1] + layer_widths[2*i+1] for i in range(n_layers//2))\n",
    "    model = layers[0]\n",
    "    for idx, l in enumerate(layers[1:-1]):\n",
    "        model = onnx.compose.merge_models(model, l, [(f\"Y_{idx}\", f\"X_{idx+1}\")])\n",
    "    if n_layers > 1:\n",
    "        model = onnx.compose.merge_models(model, layers[-1], [(f\"Y_{n_layers-2}\", f\"X_{n_layers-1}\")])\n",
    "    return model, n_params\n",
    "print([make_multilayer(i)[1] for i in range(2, 11)])\n",
    "onnx.checker.check_model(make_multilayer(3)[0])\n",
    "print(list(make_multilayer(3, [N, N, N, N, N, N, N])[1] for N in range(10, 250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done generating\n"
     ]
    }
   ],
   "source": [
    "from compiler import parsemodel, fpgamodule\n",
    "WIDTH = 240\n",
    "DEPTH = 3\n",
    "onnx_model = make_multilayer(DEPTH, [WIDTH for i in range(2*DEPTH + 1)])[0]\n",
    "spec = fpgamodule.FPGASpec(120, 600_000, 2_700_000, 100_000)\n",
    "fpga_module = parsemodel.parse_model(onnx_model, WIDTH, spec)\n",
    "fpga_module.alloc_regs()\n",
    "fpga_module.alloc_bram()\n",
    "sv = fpga_module.make_sv()\n",
    "with open(\"dummy_model.sv\", \"w\") as f:\n",
    "    f.write(sv)\n",
    "print(\"done generating\")\n",
    "onnx.save(onnx_model, \"testmodel.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      " +C weight_0: int8:(75, 75):36,13,-23,65,-46...\n",
      " +C bias_0: int32:(75,):29,-119,-74,63,-35...\n",
      " +C weight_1: int8:(75, 75):114,70,-57,73,57...\n",
      " +C bias_1: int32:(75,):-82,124,97,-28,-34...\n",
      " +C weight_2: int8:(75, 75):-91,-21,30,-17,-103...\n",
      " +C bias_2: int32:(75,):-59,-47,30,-53,73...\n",
      " +I X_0: int8:(75,):1,1,1,1,1...\n",
      "MatMulInteger(X_0, weight_0) -> XMM32_0\n",
      " + XMM32_0: int32:(75,):925,-290,-188,-87,261...\n",
      "Add(XMM32_0, bias_0) -> XMMB32_0\n",
      " + XMMB32_0: int32:(75,):954,-409,-262,-24,226...\n",
      "Cast(XMMB32_0) -> XMMB8_0\n",
      " + XMMB8_0: int8:(75,):-70,103,-6,-24,-30...\n",
      "Relu(XMMB8_0) -> Y_0\n",
      " + Y_0: int8:(75,):0,103,0,0,0...\n",
      "MatMulInteger(Y_0, weight_1) -> XMM32_1\n",
      " + XMM32_1: int32:(75,):2154,75778,6840,-56400,36...\n",
      "Add(XMM32_1, bias_1) -> XMMB32_1\n",
      " + XMMB32_1: int32:(75,):2072,75902,6937,-56428,2...\n",
      "Cast(XMMB32_1) -> XMMB8_1\n",
      " + XMMB8_1: int8:(75,):24,126,25,-108,2...\n",
      "Relu(XMMB8_1) -> Y_1\n",
      " + Y_1: int8:(75,):24,126,25,0,2...\n",
      "MatMulInteger(Y_1, weight_2) -> XMM32_2\n",
      " + XMM32_2: int32:(75,):-29432,-12120,-3125,57055,21279...\n",
      "Add(XMM32_2, bias_2) -> XMMB32_2\n",
      " + XMMB32_2: int32:(75,):-29491,-12167,-3095,57002,21352...\n",
      "Cast(XMMB32_2) -> XMMB8_2\n",
      " + XMMB8_2: int8:(75,):-51,121,-23,-86,104...\n",
      "Relu(XMMB8_2) -> Y_2\n",
      " + Y_2: int8:(75,):0,121,0,0,104...\n",
      "[array([  0, 121,   0,   0, 104,  62,  79,   0,   0,  87, 101,   0,  66,\n",
      "        65,   0,  42, 118,   0,   0,  63,  55,   0,  34,   0, 125, 104,\n",
      "        25,  76,   0,  88,   0,   0,  47,  21,  40,  36,   0,   0,   0,\n",
      "         0,   0,  53,  23,   0,  79,   0,   0,  15,   0,  52,   0,   0,\n",
      "        12,   8,  44,  34, 114,  61,  61,   0,   0,  88, 100,   0,   8,\n",
      "        98,   0,  97,   0, 121,  57,   0,  53,   2,  71], dtype=int8)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "from onnx.reference import ReferenceEvaluator\n",
    "\n",
    "providers = [\"CPUExecutionProvider\"]\n",
    "print(ort.get_available_providers())\n",
    "options = ort.SessionOptions()\n",
    "options.enable_profiling=False\n",
    "sess = ReferenceEvaluator(\"testmodel.onnx\", verbose = 4)\n",
    "x_test = np.ones(WIDTH).astype(np.int8)\n",
    "res = sess.run([f\"Y_{DEPTH-1}\"], {\"X_0\": x_test})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  36   13  -23 ...   46  -58   87]\n",
      " [  87  -93  -33 ...   96  -11  -25]\n",
      " [  14   -6  -88 ... -112   66   -4]\n",
      " ...\n",
      " [-107 -102    3 ...  -35   25 -118]\n",
      " [ 126  -24   98 ...  -48   26  -61]\n",
      " [ -43   -9  -57 ...   84   22   48]]\n",
      "[  29 -119  -74   63  -35   -9   45  106  -80   87  -18 -124   31   81\n",
      "  114  -89  -48   84   15   97    2  -45   28  -46  -68   97   76   30\n",
      "  -72   99   11  110    4  -65  -33   -7  -20   41   44   -9  -46   40\n",
      "  -19  114 -112   46   48   50   80   49   33  -54  -10   74  -33  -60\n",
      "   94   35  -16   30  -57  -76   29   47   23   35  -66  -25  -91   18\n",
      "    8   40   96   16  -85]\n",
      "[[ 114   70  -57 ...  -94 -122 -118]\n",
      " [  36  -71  123 ...  -76   41  -11]\n",
      " [ -90 -128   31 ... -100  114 -100]\n",
      " ...\n",
      " [  45  108   46 ...   54  -39   79]\n",
      " [ -84  -91   64 ...   50  -23  103]\n",
      " [  35 -106   30 ...   85   93   96]]\n",
      "[ -82  124   97  -28  -34   79 -124 -112 -112  -18  -31   22   60   24\n",
      " -110  -35  -19  -32  -65  -90 -100  121   11  -79  116  -56   62  -28\n",
      "  -93   38  -49  -55  124 -111  -84  109    3  -87 -118  -14  -30 -125\n",
      "   71   40   64 -100 -117 -110  -48   -5   87  -96  -59  110  -18  115\n",
      "  125  104  -86   22  -59  104  -49 -114    1   18   11   96   -5   33\n",
      "  -38 -108   -6  -31  -54]\n",
      "[[ -91  -21   30 ...  -65   12   28]\n",
      " [ -59  -37    3 ...   -1  -28  -95]\n",
      " [  58  126  -98 ...   78  -35  -35]\n",
      " ...\n",
      " [ 108  115  -47 ...   30   98 -104]\n",
      " [ -99  108  -24 ...  112  -89   93]\n",
      " [ -21   43 -107 ... -120   29 -122]]\n",
      "[ -59  -47   30  -53   73   12  -18    6   62  -47  112   68  -70  -68\n",
      "  -67  -36  -20  -51 -109 -101  116  -79   -4  -22    8    2  -46   -9\n",
      "  -88 -128   86   12  -60  126  -11  106   90   41  -30  -40   -6   28\n",
      "   24  -12   51  -17  -71  -50  -62   76  -12    9   33   69   59   77\n",
      "    5  -61  -21  -71   34    5   -5   45  -92 -120   45  -81  108  -73\n",
      "  -97 -113  103   68   70]\n"
     ]
    }
   ],
   "source": [
    "for init in onnx_model.graph.initializer:\n",
    "    print(onnx.numpy_helper.to_array(init).astype(np.int8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bespoke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
